{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Fetch dataset\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "\n",
    "# Explicitly create a copy of y to avoid SettingWithCopyWarning\n",
    "y = y.copy()\n",
    "\n",
    "# Convert Diagnosis to binary 0 or 1\n",
    "y['Diagnosis'] = y['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Combine features and targets into a single DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Diagnosis'\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_data = pd.concat([x_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Diagnosis (M = malignant = 1, B = benign = 0)\n",
    "train_data.corr(numeric_only=True)[target_column].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['concave_points3',]\n",
    "# filter chosen features\n",
    "x_train = x_train[features]\n",
    "x_test = x_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    plt.figure(figsize=(8,4))  # Create a new figure for each plot\n",
    "    sns.histplot(data=train_data, x=f, kde=True)  # Plot histogram with KDE\n",
    "    plt.title(f'Distribution of {f}')  # Add a title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))  # Create a side-by-side layout\n",
    "\n",
    "    # Scatter plot: Feature vs Target\n",
    "    train_data.plot(kind='scatter', x=feature, y=target_column, alpha=0.4, ax=axes[0])\n",
    "    axes[0].set_title(f'Scatter: {feature} vs {target_column}')\n",
    "\n",
    "    # Box plot: Distribution of Feature\n",
    "    train_data[feature].plot(kind='box', ax=axes[1])\n",
    "    axes[1].set_title(f'Box Plot: {feature}')\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout for better spacing\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns):\n",
    "    \"\"\"\n",
    "    Remove outliers using the IQR method for specified columns.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)  # First quartile (25%)\n",
    "        Q3 = df[col].quantile(0.75)  # Third quartile (75%)\n",
    "        IQR = Q3 - Q1  # Interquartile Range\n",
    "\n",
    "        # Define bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Filter the DataFrame\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(train_data.shape)\n",
    "train_data_clean = remove_outliers(train_data, features)\n",
    "print(train_data_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting x_train and y_train\n",
    "x_train = train_data_clean[features].to_numpy()\n",
    "y_train = train_data_clean[target_column].to_numpy()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_norm = scaler.fit_transform(x_train)\n",
    "print(f\"Peak to Peak range by column in Raw        X:{np.ptp(x_train, axis=0)}\")\n",
    "print(f\"Peak to Peak range by column in Normalized X:{np.ptp(x_norm, axis=0)}\")\n",
    "x_train = x_norm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
